{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "njbpbuGqSSrs"
   },
   "source": [
    "Generative Adversarial Networks (GANs)\n",
    "======\n",
    "This code implements a Deep Convolutional GAN (DCGAN), a GAN with only convolutional layers in the encoder and decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install conda=23.7.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 22.11.1\n",
      "  latest version: 23.7.3\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.7.3\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda update -n base -c defaults conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 22.11.1\n",
      "  latest version: 23.7.3\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.7.3\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install pytorch torchvision -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/atanumondal/anaconda3/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: filelock in /Users/atanumondal/anaconda3/lib/python3.10/site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/atanumondal/anaconda3/lib/python3.10/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: sympy in /Users/atanumondal/anaconda3/lib/python3.10/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/atanumondal/anaconda3/lib/python3.10/site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in /Users/atanumondal/anaconda3/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/atanumondal/anaconda3/lib/python3.10/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/atanumondal/anaconda3/lib/python3.10/site-packages/mpmath-1.2.1-py3.10.egg (from sympy->torch) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "wLUS1iQFSSru"
   },
   "outputs": [],
   "source": [
    "# install pytorch (http://pytorch.org/) if run from Google Colaboratory\n",
    "import sys\n",
    "if 'google.colab' in sys.modules and 'torch' not in sys.modules:\n",
    "    from os.path import exists\n",
    "    from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "    platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "    cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
    "    accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
    "\n",
    "    !pip3 install https://download.pytorch.org/whl/{accelerator}/torch-1.1.0-{platform}-linux_x86_64.whl\n",
    "    !pip3 install https://download.pytorch.org/whl/{accelerator}/torchvision-0.3.0-{platform}-linux_x86_64.whl\n",
    "\n",
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijUaIqdWSSrv"
   },
   "source": [
    "Parameter Settings\n",
    "-------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "xUhJ6OEJSSrv"
   },
   "outputs": [],
   "source": [
    "latent_dims = 10\n",
    "num_epochs = 1\n",
    "batch_size = 128\n",
    "#batch_size=32\n",
    "#learning_rate = 2e-4\n",
    "learning_rate=0.1\n",
    "use_gpu = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sqMjHV1XSSrv"
   },
   "source": [
    "MNIST Data Loading\n",
    "-------------------\n",
    "\n",
    "MNIST images show digits from 0-9 in 28x28 grayscale images. We scale to 64x64 so we can have a deeper architecture with more down-sampling steps. The images are normalized and centerd around 0, which gives a slight performance boost during training. We create both a training set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from torch.utils.data import SubsetRandomSampler\\n\\n# Define a subset size (e.g., 10% of the dataset)\\nsubset_fraction = 0.1\\nnum_samples = int(len(dataset) * subset_fraction)\\n\\n# Create a random subset sampler\\nsubset_sampler = SubsetRandomSampler(range(num_samples))\\n\\n# Create a dataloader using the subset sampler\\ntrain_dataloader = DataLoader(dataset, batch_size=batch_size, sampler=subset_sampler)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from torch.utils.data import SubsetRandomSampler\n",
    "\n",
    "# Define a subset size (e.g., 10% of the dataset)\n",
    "subset_fraction = 0.1\n",
    "num_samples = int(len(dataset) * subset_fraction)\n",
    "\n",
    "# Create a random subset sampler\n",
    "subset_sampler = SubsetRandomSampler(range(num_samples))\n",
    "\n",
    "# Create a dataloader using the subset sampler\n",
    "train_dataloader = DataLoader(dataset, batch_size=batch_size, sampler=subset_sampler)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from torch.utils.data import SubsetRandomSampler\\n\\nsubset_fraction = 0.1  # Use 10% of the dataset\\nnum_train_samples = int(len(train_dataset) * subset_fraction)\\nnum_test_samples = int(len(test_dataset) * subset_fraction)\\n\\n# Create random samplers for training and test subsets\\ntrain_sampler = SubsetRandomSampler(range(num_train_samples))\\ntest_sampler = SubsetRandomSampler(range(num_test_samples))\\n\\n# Create dataloaders for the subsets\\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\\ntest_dataloader = DataLoader(test_dataset, batch_size=batch_size, sampler=test_sampler)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from torch.utils.data import SubsetRandomSampler\n",
    "\n",
    "subset_fraction = 0.1  # Use 10% of the dataset\n",
    "num_train_samples = int(len(train_dataset) * subset_fraction)\n",
    "num_test_samples = int(len(test_dataset) * subset_fraction)\n",
    "\n",
    "# Create random samplers for training and test subsets\n",
    "train_sampler = SubsetRandomSampler(range(num_train_samples))\n",
    "test_sampler = SubsetRandomSampler(range(num_test_samples))\n",
    "\n",
    "# Create dataloaders for the subsets\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, sampler=test_sampler)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'img_transform = transforms.Compose([\\n    transforms.Resize(32),  # Change the size to 32x32 or another desired size\\n    transforms.ToTensor(),\\n    transforms.Normalize((0.5,), (0.5,))\\n])\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"img_transform = transforms.Compose([\n",
    "    transforms.Resize(32),  # Change the size to 32x32 or another desired size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Qc87eEuwSSrw"
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "#download=False done\n",
    "train_dataset = MNIST(root='./data/MNIST', download=True, train=True, transform=img_transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = MNIST(root='./data/MNIST', download=True, train=False, transform=img_transform)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import SubsetRandomSampler\n",
    "\n",
    "subset_fraction = 0.1  # Use 10% of the dataset\n",
    "num_train_samples = int(len(train_dataset) * subset_fraction)\n",
    "num_test_samples = int(len(test_dataset) * subset_fraction)\n",
    "\n",
    "# Create random samplers for training and test subsets\n",
    "train_sampler = SubsetRandomSampler(range(num_train_samples))\n",
    "test_sampler = SubsetRandomSampler(range(num_test_samples))\n",
    "\n",
    "# Create dataloaders for the subsets\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, sampler=test_sampler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3NKvCmiPSSrw"
   },
   "source": [
    "GAN Definition\n",
    "-----------------------\n",
    "We use a convolutional generator and discriminator, which generally gives better performance than fully connected versions that have the same number of parameters.\n",
    "\n",
    "Kernel size 4 is used to avoid biasing problems described here: https://distill.pub/2016/deconv-checkerboard/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "kQgwcIUKSSrw",
    "outputId": "3a2a17f5-77ab-4aea-971e-5d2d1291402d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters for generator: 12656257 and discriminator: 11033985\n"
     ]
    }
   ],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, d=128):\n",
    "        super(Generator, self).__init__()\n",
    "        self.deconv1 = nn.ConvTranspose2d(100, d*8, 4, 1, 0)\n",
    "        self.deconv1_bn = nn.BatchNorm2d(d*8)\n",
    "        self.deconv2 = nn.ConvTranspose2d(d*8, d*4, 4, 2, 1)\n",
    "        self.deconv2_bn = nn.BatchNorm2d(d*4)\n",
    "        self.deconv3 = nn.ConvTranspose2d(d*4, d*2, 4, 2, 1)\n",
    "        self.deconv3_bn = nn.BatchNorm2d(d*2)\n",
    "        self.deconv4 = nn.ConvTranspose2d(d*2, d, 4, 2, 1)\n",
    "        self.deconv4_bn = nn.BatchNorm2d(d)\n",
    "        self.deconv5 = nn.ConvTranspose2d(d, 1, 4, 2, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # x = F.relu(self.deconv1(input))\n",
    "        x = F.relu(self.deconv1_bn(self.deconv1(input)))\n",
    "        x = F.relu(self.deconv2_bn(self.deconv2(x)))\n",
    "        x = F.relu(self.deconv3_bn(self.deconv3(x)))\n",
    "        x = F.relu(self.deconv4_bn(self.deconv4(x)))\n",
    "        x = torch.tanh(self.deconv5(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, d=128):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, d, 4, 2, 1)\n",
    "        self.conv2 = nn.Conv2d(d, d*2, 4, 2, 1)\n",
    "        self.conv2_bn = nn.BatchNorm2d(d*2)\n",
    "        self.conv3 = nn.Conv2d(d*2, d*4, 4, 2, 1)\n",
    "        self.conv3_bn = nn.BatchNorm2d(d*4)\n",
    "        self.conv4 = nn.Conv2d(d*4, d*8, 4, 2, 1)\n",
    "        self.conv4_bn = nn.BatchNorm2d(d*8)\n",
    "        self.conv5 = nn.Conv2d(d*8, 1, 4, 1, 0)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = F.leaky_relu(self.conv1(input), 0.2)\n",
    "        x = F.leaky_relu(self.conv2_bn(self.conv2(x)), 0.2)\n",
    "        x = F.leaky_relu(self.conv3_bn(self.conv3(x)), 0.2)\n",
    "        x = F.leaky_relu(self.conv4_bn(self.conv4(x)), 0.2)\n",
    "        x = torch.sigmoid(self.conv5(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if use_gpu and torch.cuda.is_available() else \"cpu\")\n",
    "generator = generator.to(device)\n",
    "discriminator = discriminator.to(device)\n",
    "\n",
    "num_params_gen = sum(p.numel() for p in generator.parameters() if p.requires_grad)\n",
    "num_params_disc = sum(p.numel() for p in discriminator.parameters() if p.requires_grad)\n",
    "print('Number of parameters for generator: %d and discriminator: %d' % (num_params_gen, num_params_disc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://chat.openai.com/share/bda17eba-f981-435f-9322-d50335284e79'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"https://chat.openai.com/share/bda17eba-f981-435f-9322-d50335284e79\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NG93kvRbSSrx"
   },
   "source": [
    "Train GAN\n",
    "--------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "48E4HH_xSSrx",
    "outputId": "a18d474c-d8fd-4504-e159-b46324dc93a8",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4.1\n",
      "4.2\n",
      "4.3\n",
      "4.4\n",
      "4.5\n",
      "5\n",
      "6\n",
      "Epoch [1 / 1] average loss generator vs. discrim.: 100.000000 vs. 73.427020\n"
     ]
    }
   ],
   "source": [
    "# GAN training can be unstable. In this case, the strong momentum\n",
    "# for the gradient prevents convergence. One possible explanation is that the\n",
    "# strong momentum does not allow the two players in the adversarial game to react\n",
    "# to each other quickly enough. Decreasing beta1 (the exponential decay for the\n",
    "# gradient moving average in [0,1], lower is faster decay) from the default 0.9\n",
    "# to 0.5 allows for quicker reactions.\n",
    "gen_optimizer = torch.optim.Adam(params=generator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "disc_optimizer = torch.optim.Adam(params=discriminator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "\n",
    "# set to training mode\n",
    "generator.train()\n",
    "discriminator.train()\n",
    "\n",
    "gen_loss_avg = []\n",
    "disc_loss_avg = []\n",
    "\n",
    "print('Training ...')\n",
    "for epoch in range(num_epochs):\n",
    "    gen_loss_avg.append(0)\n",
    "    disc_loss_avg.append(0)\n",
    "    num_batches = 0\n",
    "    print(1)\n",
    "    for image_batch, _ in train_dataloader:\n",
    "        print(2)\n",
    "        # get dataset image and create real and fake labels for use in the loss\n",
    "        image_batch = image_batch.to(device)\n",
    "        label_real = torch.ones(image_batch.size(0), device=device)\n",
    "        label_fake = torch.zeros(image_batch.size(0), device=device)\n",
    "        print(3)\n",
    "        # generate a batch of images from samples of the latent prior\n",
    "        latent = torch.randn(image_batch.size(0), 100, 1, 1, device=device)\n",
    "        fake_image_batch = generator(latent)\n",
    "        print(4)\n",
    "        # train discriminator to correctly classify real and fake\n",
    "        # (detach the computation graph of the generator and the discriminator,\n",
    "        # so that gradients are not backpropagated into the generator)\n",
    "        real_pred = discriminator(image_batch).squeeze()\n",
    "        print(4.1)\n",
    "        fake_pred = discriminator(fake_image_batch.detach()).squeeze()\n",
    "        print(4.2)\n",
    "        disc_loss = 0.75 * (\n",
    "            F.binary_cross_entropy(real_pred, label_real) +\n",
    "            F.binary_cross_entropy(fake_pred, label_fake))\n",
    "        print(4.3)\n",
    "        disc_optimizer.zero_grad()\n",
    "        print(4.4)\n",
    "        disc_loss.backward()\n",
    "        print(4.5)\n",
    "        disc_optimizer.step()\n",
    "        print(5)\n",
    "        # train generator to output an image that is classified as real\n",
    "        fake_pred = discriminator(fake_image_batch).squeeze()\n",
    "        gen_loss = F.binary_cross_entropy(fake_pred, label_real)\n",
    "\n",
    "        gen_optimizer.zero_grad()\n",
    "        gen_loss.backward()\n",
    "        gen_optimizer.step()\n",
    "        print(6)\n",
    "        gen_loss_avg[-1] += gen_loss.item()\n",
    "        disc_loss_avg[-1] += disc_loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    gen_loss_avg[-1] /= num_batches\n",
    "    disc_loss_avg[-1] /= num_batches\n",
    "    print('Epoch [%d / %d] average loss generator vs. discrim.: %f vs. %f' %\n",
    "          (epoch+1, num_epochs, gen_loss_avg[-1], disc_loss_avg[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_KCAeOgiSSry"
   },
   "source": [
    "Plot Training Curves\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0qsah4M3SSry",
    "outputId": "98cff46b-f36b-431a-d2e9-17b180e6fcd5"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.ion()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(gen_loss_avg, label='generator')\n",
    "plt.plot(disc_loss_avg, label='discriminator')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YpNA8hZZSSry"
   },
   "source": [
    "Alternatively: Load Pre-Trained GAN\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "60iRhUvYSSry"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading ...\n"
     ]
    },
    {
     "ename": "TimeoutError",
     "evalue": "[Errno 60] Operation timed out",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./pretrained\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdownloading ...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlretrieve\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttp://geometry.cs.ucl.ac.uk/creativeai/pretrained/dcgan.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./pretrained/dcgan.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlretrieve (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://geometry.cs.ucl.ac.uk/creativeai/pretrained/dcgan_discriminator.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./pretrained/dcgan_discriminator.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m generator\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./pretrained/dcgan.pth\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/urllib/request.py:239\u001b[0m, in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;124;03mRetrieve a URL into a temporary location on disk.\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;124;03mdata file as well as the resulting HTTPMessage object.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    237\u001b[0m url_type, path \u001b[38;5;241m=\u001b[39m _splittype(url)\n\u001b[0;32m--> 239\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mclosing(\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[1;32m    240\u001b[0m     headers \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39minfo()\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m# Just return the local path and the \"headers\" for file://\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# URLs. No sense in performing a copy unless requested.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/urllib/request.py:214\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    213\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/urllib/request.py:517\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    514\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[1;32m    516\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[0;32m--> 517\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[1;32m    520\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/urllib/request.py:534\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    533\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[0;32m--> 534\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[1;32m    535\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/urllib/request.py:494\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    493\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 494\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    496\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/urllib/request.py:1375\u001b[0m, in \u001b[0;36mHTTPHandler.http_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[0;32m-> 1375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTTPConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/urllib/request.py:1350\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[1;32m   1349\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[0;32m-> 1350\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1351\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m   1352\u001b[0m     h\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py:1377\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1377\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1379\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py:320\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    322\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py:281\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 281\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mTimeoutError\u001b[0m: [Errno 60] Operation timed out"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "if not os.path.isdir('./pretrained'):\n",
    "    os.makedirs('./pretrained')\n",
    "print('downloading ...')\n",
    "urllib.request.urlretrieve (\"http://geometry.cs.ucl.ac.uk/creativeai/pretrained/dcgan.pth\", \"./pretrained/dcgan.pth\")\n",
    "urllib.request.urlretrieve (\"http://geometry.cs.ucl.ac.uk/creativeai/pretrained/dcgan_discriminator.pth\", \"./pretrained/dcgan_discriminator.pth\")\n",
    "generator.load_state_dict(torch.load('./pretrained/dcgan.pth'))\n",
    "discriminator.load_state_dict(torch.load('./pretrained/dcgan_discriminator.pth'))\n",
    "print('done')\n",
    "\n",
    "# this is how the GAN parameters can be saved:\n",
    "# torch.save(generator.state_dict(), './pretrained/my_dcgan.pth')\n",
    "# torch.save(discriminator.state_dict(), './pretrained/my_dcgan_discriminator.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRl9ydJISSry"
   },
   "source": [
    "Interpolate in Latent Space\n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wwxBifTtSSry",
    "outputId": "12f91d04-86c2-44da-8c0f-5d2e25214b5c",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()\n",
    "\n",
    "import torchvision.utils\n",
    "\n",
    "generator.eval()\n",
    "\n",
    "def interpolation(lambda1, model, latent_1, latent_2):\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # interpolation of the two latent vectors\n",
    "        inter_latent = lambda1* latent_1 + (1- lambda1) * latent_2\n",
    "\n",
    "        # reconstruct interpolated image\n",
    "        inter_latent = inter_latent.to(device)\n",
    "        inter_image = model(inter_latent)\n",
    "        inter_image = inter_image.cpu()\n",
    "\n",
    "        return inter_image\n",
    "\n",
    "# sample two latent vectors from the standard normal distribution\n",
    "latent_1 = torch.randn(1, 100, 1, 1, device=device)\n",
    "latent_2 = torch.randn(1, 100, 1, 1, device=device)\n",
    "\n",
    "# interpolation lambdas\n",
    "lambda_range=np.linspace(0,1,10)\n",
    "\n",
    "fig, axs = plt.subplots(2,5, figsize=(15, 6))\n",
    "fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "axs = axs.ravel()\n",
    "\n",
    "for ind,l in enumerate(lambda_range):\n",
    "    inter_image=interpolation(float(l), generator, latent_1, latent_2)\n",
    "\n",
    "    inter_image = to_img(inter_image)\n",
    "\n",
    "    image = inter_image.numpy()\n",
    "\n",
    "    axs[ind].imshow(image[0,0,:,:], cmap='gray')\n",
    "    axs[ind].set_title('lambda_val='+str(round(l,1)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yeVAvG-tSSrz"
   },
   "source": [
    "Sample Latent Vector from Prior (GAN as Generator)\n",
    "-------------------------------------------------\n",
    "\n",
    "GANs usually generate higher-quality results than VAEs or plain Autoencoders, since the distribution of generated digits is more focused on the modes of the real data distribution (see tutorial slides). However, they are harder to train and don't have an encoder, which means the inference of a latent code from a given image is not possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5UTew5iLSSrz",
    "outputId": "90818e5f-405d-48f4-e2c2-0fdb4f20165c"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()\n",
    "\n",
    "import torchvision.utils\n",
    "\n",
    "generator.eval()\n",
    "\n",
    "def to_img(x):\n",
    "    x = 0.5 * (x + 1)\n",
    "    x = x.clamp(0, 1)\n",
    "    return x\n",
    "\n",
    "def show_image(img):\n",
    "    img = to_img(img)\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    # sample latent vectors from the standard normal distribution\n",
    "    latent = torch.randn(image_batch.size(0), 100, 1, 1, device=device)\n",
    "    fake_image_batch = generator(latent)\n",
    "    fake_image_batch = fake_image_batch.cpu()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    show_image(torchvision.utils.make_grid(fake_image_batch.data[:100],10,5))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
